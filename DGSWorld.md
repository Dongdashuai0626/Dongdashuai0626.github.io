### 现实与模拟的无缝对接：DSG-World如何利用双状态视频构建3D世界模型

想象一下，如果机器人能够像我们一样“看”懂世界，不仅能识别物体，还能理解物体的运动和遮挡关系，甚至能预测物体移动后的场景样貌。这将为机器人交互、虚拟现实和自动驾驶等领域带来革命性的变化。然而，从有限的、部分遮挡的真实世界观测中构建一个既高效又符合物理规律的3D世界模型，一直是一项艰巨的挑战。

[cite\_start]近日，来自浙江大学的研究人员在他们最新的论文《DSG-World: Learning a 3D Gaussian World Model from Dual State Videos》中，提出了一种名为 **DSG-World** 的创新框架，为解决这一难题提供了全新的思路 [cite: 2]。该方法的核心思想是利用同一场景在两种不同物体配置下的“双状态”观测，从而高效、精确地构建出可交互的3D世界。

-----

#### 现有方法的困境

在深入了解DSG-World之前，我们先来看看传统方法面临的瓶颈。

当前的3D世界建模方法大致可分为两类：

1.  [cite\_start]**基于隐式生成模型的方法**：这类方法通常难以训练，并且缺乏明确的3D结构和物理一致性，导致它们在需要精确交互和模拟的任务中表现不佳 [cite: 6]。
2.  [cite\_start]**基于显式3D表示的方法**：虽然3D高斯溅射（3D Gaussian Splatting）等技术能够显式地重建场景，但当处理单个状态的观测时，常常因为物体遮挡而需要进行复杂的“多阶段”处理，例如分割、背景补全和图像修复（inpainting） [cite: 7, 19, 21][cite\_start]。这些步骤不仅增加了系统的复杂性，还容易引入和累积错误，导致最终生成的场景失真或模糊 [cite: 20, 22][cite\_start]。如下图(a)所示，传统的单状态流程需要经过分割、后处理和修复等多个步骤，容易产生瑕疵 [cite: 46]。

![alt text](image-2.png)

#### DSG-World的核心创新：双状态观测

[cite\_start]为了克服上述挑战，DSG-World独辟蹊径，利用了同一场景下两种被轻微扰动的观测状态 [cite: 8]。想象一下，桌子上有一个杯子，我们拍一张照片（状态一）；然后把杯子挪到桌子的另一个位置，再拍一张照片（状态二）。

[cite\_start]这两种状态的视频提供了互补的可见性 [cite: 9][cite\_start]。在状态一中被杯子遮挡的桌面区域，在状态二中可能就变得可见了 [cite: 55][cite\_start]。这种互补信息极大地缓解了状态转换中的遮挡问题，使得场景重建更加稳定和完整 [cite: 9]。

[cite\_start]DSG-World是一个端到端的框架，它直接从这两种状态的观测中构建一个分割感知的3D高斯世界模型，完全无需进行图像修复或依赖密集的观测数据 [cite: 10, 13]。

-----

#### DSG-World是如何工作的？

DSG-World的实现流程精巧而高效，主要包含以下几个关键步骤，如下图所示：

![alt text](image.png)

1.  [cite\_start]**双向对齐 (Bidirectional Alignment)**：框架首先为两个状态分别构建高斯场（$G\_1$ 和 $G\_2$） [cite: 153][cite\_start]。然后，它通过已知的物体变换关系，将状态一的高斯场“转换”到状态二的配置下，并将其渲染结果与状态二的真实观测进行比较，反之亦然 [cite: 161, 164][cite\_start]。这种双向的监督强制模型学习到两个状态之间的光度和语义一致性，确保物体在不同配置下的对应关系是准确的 [cite: 58, 169]。

2.  [cite\_start]**伪状态引导对齐 (Pseudo-state Guided Alignment)**：为了进一步提升模型的泛化能力，研究者们引入了一个“伪中间状态” [cite: 12, 171][cite\_start]。这个虚拟状态是通过几何约束构建的，作为两个真实观测状态之间的共享参考空间 [cite: 59, 172][cite\_start]。通过将两个高斯场都转换到这个共同的伪状态下进行比较和对齐，模型可以更好地弥合两个输入状态之间的差异，从而更有效地推广到未曾见过的中间场景配置中 [cite: 176, 182]。

3.  [cite\_start]**协同协修剪 (Collaborative Co-Pruning)**：由于初始分割可能不完美，状态转换后可能会留下一些错位或多余的“浮动”高斯点 [cite: 155, 185][cite\_start]。DSG-World设计了一种协同修剪策略 [cite: 60][cite\_start]。它通过检查一个转换后的高斯点能否在目标状态的几何中找到可靠的对应点来滤除这些异常值 [cite: 186][cite\_start]。这种双向的几何一致性检查能有效移除冗余或错位的成分，使模型更加干净、精确 [cite: 192]。

4.  [cite\_start]**协同粘贴 (Co-pasting)**：与传统方法依赖算法“脑补”被遮挡的背景不同，DSG-World利用双状态的互补性，直接从另一个状态中“粘贴”被遮挡的背景高斯点来完成场景补全 [cite: 249]。这种方法我们称之为“协同粘贴”，它比基于修复的方法更真实、更准确。

-----

#### 惊艳的实验结果

[cite\_start]为了验证方法的有效性，研究团队在自己构建的包含合成和真实场景的数据集上进行了大量实验 [cite: 199][cite\_start]。他们将DSG-World与多种基于分割和修复的主流方法进行了比较，如GaussianEditor、Gaussian Grouping和GaussianCut等 [cite: 216, 218]。

**定性比较**

[cite\_start]从视觉效果上看，DSG-World的表现明显优于其他方法。如下图所示，在模拟新的场景状态时，传统方法往往会出现物体边界模糊、背景损坏或产生“浮动”伪影等问题 [cite: 226, 237][cite\_start]。而DSG-World生成的场景则非常干净、完整，与真实的场景配置高度一致 [cite: 226]。

![alt text](image-1.png)

**定量比较**

[cite\_start]在量化指标上，DSG-World同样取得了最佳性能。如下表所示，无论是在合成数据集还是真实世界数据集上，DSG-World在峰值信噪比（PSNR）和结构相似性（SSIM）两项关键指标上都遥遥领先 [cite: 242]。这表明其生成的场景不仅在像素层面更接近真实情况，在结构上也保持了高度的保真度。

| 类型 | 模型 | Sim PSNR (↑) | Real PSNR (↑) |
| :--- | :--- | :--- | :--- |
| 分割 | GaussianEditor | 25.82 | 23.25 |
| | Gaussian Grouping | 26.22 | 22.74 |
| | Gaussiancut | 26.79 | 23.43 |
| 分割+修复 | Gaussian Grouping\*+knn | 29.31 | 23.28 |
| | DecoupledGaussian+remesh | 29.50 | 24.28 |
| | Graphcut+depth | 30.88 | 24.40 |
| **双状态** | **DSG-world (ours)** | **38.37** | **27.52** |

[cite\_start]*表格数据简化自原论文表格1* [cite: 245]

[cite\_start]消融实验也证明了其各个组件的有效性，特别是“伪状态引导对齐”策略，它对性能提升起到了至关重要的作用，因为它能有效解决仅靠两个状态无法完全消除的遮挡模糊性问题 [cite: 256, 257]。

-----

#### 局限性与未来展望

[cite\_start]尽管DSG-World表现出色，但研究人员也坦诚地指出了其当前的一些局限性。例如，该方法要求两个状态的观测具有互补性，如果物体移动范围过小，导致某些区域在两个状态下都被遮挡，那么重建的准确性就会受到影响 [cite: 272][cite\_start]。此外，当前模型没有考虑光照变化，移动物体后其静态的阴影会影响真实感 [cite: 273]。

[cite\_start]未来，将光照重渲染（relighting）等技术融入框架，将有望进一步提升模拟的逼真度 [cite: 274]。

#### 结论

[cite\_start]DSG-World通过一种巧妙的双状态观测策略，成功地绕开了传统3D世界建模中对复杂后处理和修复流程的依赖，为构建高效、精确且可交互的3D世界模型提供了一条全新的路径 [cite: 277, 278][cite\_start]。它不仅能够高保真地渲染场景，还能支持对物体的实时操控和模拟，在机器人技术、虚实转换（real-to-simulation）等领域展现出巨大的应用潜力 [cite: 280]。我们有理由相信，这项工作将推动相关领域的研究迈向一个新的台阶。